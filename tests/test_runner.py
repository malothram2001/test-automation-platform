import os
import shutil
# Disable auto-loading of 3rd-party pytest plugins (like browserstack)
os.environ["PYTEST_DISABLE_PLUGIN_AUTOLOAD"] = "1"
import sys
import pytest
import allure_pytest  # pip install allure-pytest
import requests
import subprocess
from dotenv import load_dotenv
from typing import Optional, List, Dict

load_dotenv()

BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")
CURRENT_PROC: Optional[subprocess.Popen] = None
STOP_FLAG = False  # New global flag to control execution flow

RESULTS_DIR = "allure-results"
REPORT_DIR = "allure-report"

# --- CONFIGURATION: Test Registry for Krishivaas Apps ---
# Define the mapping of App Types -> Modules -> Script Paths here.
# TEST_REGISTRY = {
#     "farmer": {
#         "login": "tests/test_cases/regular_farmer_test_cases/test_login_pytest.py",
#         "onboarding": "tests/regular_farmer/test_onboarding_pytest.py",
#         "dashboard": "tests/regular_farmer/test_dashboard_pytest.py",
#         "crop_advisory": "tests/regular_farmer/test_crop_advisory_pytest.py",
#     },
#     "client": {
#         "login": "tests/test_cases/regular_client_test_cases/test_login_pytest.py",
#         "orders": "tests/regular_client/test_orders.py",
#         "payments": "tests/regular_client/test_payments.py",
#     },
#     "state_farmer": {
#         "login": "tests/state_farmer/test_login.py",
#         "schemes": "tests/state_farmer/test_schemes.py",
#         "subsidy": "tests/state_farmer/test_subsidy.py",
#     },
#     "state_client": {
#         "login": "tests/state_client/test_login.py",
#         "reports": "tests/state_client/test_reports.py",
#         "audit": "tests/state_client/test_audit.py",
#     }
# }

def _ensure_clean_allure_dirs(project_root: str) -> None:
    os.makedirs(os.path.join(project_root, RESULTS_DIR), exist_ok=True)
    # Clean report dir (html) so you donâ€™t open an old report
    report_path = os.path.join(project_root, REPORT_DIR)
    if os.path.isdir(report_path):
        shutil.rmtree(report_path, ignore_errors=True)

def generate_report(project_root: Optional[str] = None) -> None:
    """
    Generates and opens Allure HTML report.
    Can be called manually or automatically.
    """
    if project_root is None:
        project_root = os.path.dirname(os.path.dirname(__file__))

    # improved command resolution
    allure_cmd = "allure"
    # specific check for user's scoop path if regular allure isn't found
    scoop_path = r"C:\Users\ram\scoop\shims\allure.cmd" 
    if os.path.exists(scoop_path):
        allure_cmd = scoop_path
    elif shutil.which("allure.cmd"):
        allure_cmd = "allure.cmd"
    
    try:
        send_log("Generating Allure HTML report...", "INFO")
        # 1. Generate
        subprocess.run(
            [allure_cmd, "generate", RESULTS_DIR, "-o", REPORT_DIR, "--clean"],
            cwd=project_root,
            check=True,
            shell=True 
        )
        send_log("Allure HTML report generated.", "SUCCESS")
        
        # 2. Open
        send_log("Opening Allure report in browser...", "INFO")
        subprocess.Popen(
            [allure_cmd, "open", REPORT_DIR],
            cwd=project_root,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            shell=True
        )
    except Exception as e:
        send_log(f"Failed to generate/open report: {e}", "FAILED")
        print(f"Report Generation Error: {e}")
        
def _generate_and_open_allure_report(project_root: str) -> None:
    """
    Generates and opens Allure HTML report.
    """
    allure_cmd = r"C:\Users\Pramo\scoop\shims\allure"

    # Fallback to system 'allure' if the hardcoded path doesn't exist
    if not os.path.exists(allure_cmd) and shutil.which("allure"):
        allure_cmd = "allure" 

    try:
        send_log("Generating Allure HTML report...", "INFO")
        subprocess.run(
            [allure_cmd, "generate", RESULTS_DIR, "-o", REPORT_DIR, "--clean"],
            cwd=project_root,
            check=True,
            shell=True
        )
        send_log("Allure HTML report generated.", "SUCCESS")
        send_log("Opening Allure report in browser...", "INFO")
        subprocess.Popen(
            [allure_cmd, "open", REPORT_DIR],
            cwd=project_root,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            shell=True
        )
    except Exception as e:
        send_log(f"Allure CLI not found or failed: {e}", "FAILED")

def notify_allure_open() -> None:
    """
    Ask backend to start Allure server (allure open/serve) and broadcast RUN_COMPLETE.
    Backend should implement POST /api/allure/start.
    """
    try:
        requests.post(f"{BACKEND_URL}/api/allure/start", timeout=10)
    except Exception:
        pass

def send_log(message: str, status: str = "INFO") -> None:
    """Send one log line to the frontend via /api/log-step."""
    try:
        requests.post(
            f"{BACKEND_URL}/api/log-step",
            json={"message": message, "status": status},
            timeout=3,
        )
    except Exception:
        # Don't break tests if backend logging fails
        pass

def run_pytest_with_logs(pytest_args, module_name: str) -> bool:
  """
  Run pytest in a subprocess and stream all stdout lines
  into the WebSocket log console.
  """
  send_module_status(module_name, "running", f"Starting {module_name} tests")
  send_log(f"==== Running {module_name} tests ====", "INFO")

  # Build command: python -m pytest <args>
  cmd = [os.sys.executable, "-m", "pytest"] + pytest_args

  proc = subprocess.Popen(
    cmd,
    stdout=subprocess.PIPE,
    stderr=subprocess.STDOUT,
    text=True,
    bufsize=1,
    cwd=os.path.dirname(os.path.dirname(__file__)),  # project root
  )

  # Stream each line to frontend
  assert proc.stdout is not None
  for line in proc.stdout:
    send_log(line.rstrip("\n"), "INFO")

  proc.wait()
  success = (proc.returncode == 0)

  if success:
    send_module_status(module_name, "completed", f"{module_name} tests passed")
    send_log(f"{module_name} tests passed", "SUCCESS")
  else:
    send_module_status(module_name, "failed", f"{module_name} tests failed")
    send_log(f"{module_name} tests failed", "FAILED")

  return success

def send_module_status(module: str, status: str, message: str = ""):
    """Notify backend which module is running/completed."""
    try:
        requests.post(
            f"{BACKEND_URL}/api/module-status",
            json={"module": module, "status": status, "message": message},
            timeout=3,
        )
    except Exception:
        # Do not break tests if backend is down
        pass

def stop_current_tests() -> bool:
    global CURRENT_PROC, STOP_FLAG
    STOP_FLAG = True  # Signal the runner loop to stop

    if CURRENT_PROC is None:
        return False

    try:
        send_log("Stopping tests on user request...", "FAILED")
        CURRENT_PROC.terminate()
        try:
            CURRENT_PROC.wait(timeout=2)
        except subprocess.TimeoutExpired:
            CURRENT_PROC.kill()
        send_log("Test process terminated.", "FAILED")
    except Exception as e:
        send_log(f"Error while stopping tests: {e}", "FAILED")
    finally:
        CURRENT_PROC = None

    return True

def run_pytest_streaming(pytest_args: list[str], module_name: str, clean_allure: bool = False) -> bool:
    """
    Run pytest in a subprocess and stream ALL stdout lines to the frontend log console.
    Also writes allure results to allure-results.
    """
    global CURRENT_PROC, STOP_FLAG

    if STOP_FLAG:
        return False

    project_root = os.path.dirname(os.path.dirname(__file__))

    send_module_status(module_name, "running", f"Starting {module_name} tests")
    send_log(f"==== Running {module_name} tests ====", "INFO")

    cmd = [
        sys.executable,
        "-m",
        "pytest",
        "-p", "allure_pytest", 
        "-s",
        "-vv",
        f"--alluredir={RESULTS_DIR}",
    ]
    if clean_allure:
        cmd.append("--clean-alluredir")

    cmd += pytest_args

    env = os.environ.copy()
    env["PYTHONIOENCODING"] = "utf-8"
    env["PYTHONUTF8"] = "1"
    env["PYTHONUNBUFFERED"] = "1" # Force unbuffered output for real-time logs

    CURRENT_PROC = subprocess.Popen(
        cmd,
        cwd=project_root,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        env=env,
    )

    proc = CURRENT_PROC
    assert proc.stdout is not None
    for line in proc.stdout:
        if STOP_FLAG:
            break # Stop reading logs immediately
        send_log(line.rstrip("\n"), "INFO")

    # If stopped, ensure we don't hang on wait()
    if STOP_FLAG:
        if proc.poll() is None:
             try:
                 proc.kill()
             except:
                 pass
             
        # FIX: Notify frontend that this specific module failed/stopped
        send_module_status(module_name, "failed", "Stopped by user")
        return False
    
    proc.wait()
    ok = proc.returncode == 0
    CURRENT_PROC = None

    if STOP_FLAG: # Double check in case flag was set during wait
        send_log("Test execution interrupted.", "FAILED")
        return False

    if ok:
        send_module_status(module_name, "completed", f"{module_name} tests passed")
        send_log(f"{module_name} tests passed", "SUCCESS")
    else:
        send_module_status(module_name, "failed", f"{module_name} tests failed")
        send_log(f"{module_name} tests failed", "FAILED")

    return ok

# def resolve_test_modules(app_type: str, module_names: Optional[List[str]] = None) -> List[Dict[str, str]]:
#     """
#     Helper to resolve a list of runnable test configs based on the app type and selected modules.
    
#     :param app_type: One of 'regular_farmer', 'regular_client', 'state_farmer', 'state_client'
#     :param module_names: List of keys (e.g. ['login', 'dashboard']). If None/Empty, runs ALL for that app.
#     :return: List of dicts suitable for 'tests_to_run'
#     """
#     app_config = TEST_REGISTRY.get(app_type.lower())
#     if not app_config:
#         send_log(f"Unknown App Type: {app_type}. Available: {list(TEST_REGISTRY.keys())}", "FAILED")
#         return []

#     resolved_tests = []
    
#     # If no specific modules selected, select ALL for this app
#     target_keys = module_names if module_names else list(app_config.keys())

#     for key in target_keys:
#         script_path = app_config.get(key.lower())
#         if script_path:
#             resolved_tests.append({"name": key.capitalize(), "path": script_path})
#         else:
#             send_log(f"Warning: Module '{key}' not found for app '{app_type}'", "WARNING")
            
#     return resolved_tests

def run_full_suite():
    """
    Runs the complete automation suite in the required order.
    1. Login
    2. Onboarding (Farmer, Farm, Crop, Boundary)
    """
    print("\n" + "="*50)
    print("   KRISHIVAAS CONTINUOUS TEST RUNNER")
    print("="*50 + "\n")
    
    # Ensure the root directory is in the python path for imports to work
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

    # Define the order of files to run. 
    # Make sure these file names match exactly what you have on your disk.
    test_files = [
        "tests/test_login_pytest.py",
        "tests/test_onboarding_pytest.py"
    ]
    
    # Check if files exist before running to avoid 'Script not found' errors
    missing_files = [f for f in test_files if not os.path.exists(f)]
    if missing_files:
        print(f"ERROR: The following test scripts were not found: {missing_files}")
        return

    # Run pytest
    # -v: verbose, -s: show print statements in console
    exit_code = pytest.main(["-v", "-s", "--alluredir=allure-results"] + test_files)
    
    if exit_code == 0:
        print("\nALL TESTS PASSED SUCCESSFULLY")
    else:
        print(f"\nTEST SUITE FINISHED WITH EXIT CODE: {exit_code}")

if __name__ == "__main__":
    run_full_suite()


def run_tests_and_get_suggestions(
    apk_path: str, 
    tests_to_run: Optional[List[Dict[str, str]]] = None,
    app_type: Optional[str] = None,
    module_names: Optional[List[str]] = None
) -> None:
    """
    Entry point called from FastAPI or CLI.
    Runs tests -> generates Allure report -> asks backend to open Allure server.
    
    :param apk_path: Path to the APK file.
    :param tests_to_run: Direct list of modules (overrides app_type logic if provided).
    :param app_type: If provided, resolves tests from TEST_REGISTRY.
    :param module_names: Specific modules to run for the app_type.
    """

    global STOP_FLAG
    STOP_FLAG = False  # Reset flag at start of new run

    project_root = os.path.dirname(os.path.dirname(__file__))

    if not os.path.exists(apk_path):
        send_log(f"APK not found at {apk_path}", "FAILED")
        return

    _ensure_clean_allure_dirs(project_root)

    send_log(f"Running tests for APK: {apk_path}", "INFO")

    # 1. Determine which tests to run
    final_test_list = []

    if tests_to_run:
        # Caller provided explicit paths
        final_test_list = tests_to_run
    elif app_type:
        # Resolve using registry
        send_log(f"Resolving modules for App: {app_type}", "INFO")
        # final_test_list = resolve_test_modules(app_type, module_names)
    else:
        # Fallback default
        send_log("No specific modules or app_type provided. Running default login test.", "WARNING")
        final_test_list = [{"name": "Login", "path": "tests/test_cases/test_login_pytest.py"}]

    if not final_test_list:
        send_log("No valid test modules found to run. Aborting.", "FAILED")
        return

    # 2. Run the tests
    overall_ok = True
    tests_executed = False # Track if any test actually ran
    for index, test_config in enumerate(final_test_list):
        if STOP_FLAG:
            send_log("Sequence stopped by user.", "WARNING")
            break
        module_name = test_config.get("name", f"Module {index + 1}")
        script_path = test_config.get("path")
        
        # Verify script exists before running
        full_script_path = os.path.join(project_root, script_path) if script_path else ""
        if not script_path or not os.path.exists(full_script_path):
            send_log(f"Skipping {module_name}: Script not found at {script_path}", "WARNING")
            continue

        # Only clean allure results on the FIRST module
        should_clean = (index == 0)

        module_ok = run_pytest_streaming(
            [script_path, f"--apk={apk_path}", "-v"],
            module_name=module_name,
            clean_allure=should_clean,
        )
        tests_executed = True # Mark that we actually ran something
        overall_ok = overall_ok and module_ok

        # Stop sequence if user requested stop
        if STOP_FLAG:
            break

    if not tests_executed:
        send_log("No tests were executed (all skipped or missing). Skipping report generation.", "WARNING")
        return
    
    # Don't generate report if stopped mid-way by user
    if STOP_FLAG:
        send_log("Tests stopped by user. Partial report available on request.", "WARNING")
        return

    if overall_ok:
        send_log("All selected modules passed", "SUCCESS")
    else:
        send_log("Some modules failed", "FAILED")

    # 3. Generate and Open Report
    generate_report(project_root)
    # notify_allure_open()

if __name__ == "__main__":
    # CLI Usage: 
    # python tests/test_runner.py <apk_path> <app_type> [module1] [module2] ...
    # Example: python tests/test_runner.py app.apk regular_farmer login dashboard

    import sys

    if len(sys.argv) < 2:
        print("Usage: python tests/test_runner.py <apk_path> [app_type] [module_names...]")
        sys.exit(1)

    apk_arg = sys.argv[1]
    app_type_arg = sys.argv[2] if len(sys.argv) > 2 else None
    modules_arg = sys.argv[3:] if len(sys.argv) > 3 else None

    run_tests_and_get_suggestions(
        apk_path=apk_arg,
        app_type=app_type_arg,
        module_names=modules_arg
    )


    